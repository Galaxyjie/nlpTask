{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The size of the dictionary is: 7613\n",
                        "The number of the train batch is: 134\n",
                        "\n",
                        "Train the RNNLM……………………\n",
                        "TextRNN(\n",
                        "  (C): Embedding(7613, 128)\n",
                        "  (W_ax): Linear(in_features=128, out_features=5, bias=False)\n",
                        "  (tanh): Tanh()\n",
                        "  (W): Linear(in_features=5, out_features=7613, bias=False)\n",
                        ")\n",
                        "Epoch: 0001 Batch: 50 /134 lost = 8.816246 ppl = 6742.9\n",
                        "Epoch: 0001 Batch: 100 /134 lost = 8.677533 ppl = 5869.55\n",
                        "Valid 4864 samples after epoch: 0001 lost = 8.558627 ppl = 5211.52\n",
                        "Saving best model\n",
                        "Epoch: 0002 Batch: 50 /134 lost = 8.386402 ppl = 4387.01\n",
                        "Epoch: 0002 Batch: 100 /134 lost = 8.240442 ppl = 3791.22\n",
                        "Valid 4864 samples after epoch: 0002 lost = 8.136429 ppl = 3416.7\n",
                        "Saving best model\n",
                        "Epoch: 0003 Batch: 50 /134 lost = 7.939141 ppl = 2804.95\n",
                        "Epoch: 0003 Batch: 100 /134 lost = 7.798598 ppl = 2437.18\n",
                        "Valid 4864 samples after epoch: 0003 lost = 7.725281 ppl = 2264.89\n",
                        "Saving best model\n",
                        "Epoch: 0004 Batch: 50 /134 lost = 7.526634 ppl = 1856.85\n",
                        "Epoch: 0004 Batch: 100 /134 lost = 7.409047 ppl = 1650.85\n",
                        "Valid 4864 samples after epoch: 0004 lost = 7.383508 ppl = 1609.23\n",
                        "Saving best model\n",
                        "Epoch: 0005 Batch: 50 /134 lost = 7.185365 ppl = 1319.97\n",
                        "Epoch: 0005 Batch: 100 /134 lost = 7.095104 ppl = 1206.05\n",
                        "Valid 4864 samples after epoch: 0005 lost = 7.113737 ppl = 1228.73\n",
                        "Saving best model\n",
                        "Epoch: 0006 Batch: 50 /134 lost = 6.917719 ppl = 1010.01\n",
                        "Epoch: 0006 Batch: 100 /134 lost = 6.849334 ppl = 943.252\n",
                        "Valid 4864 samples after epoch: 0006 lost = 6.913557 ppl = 1005.82\n",
                        "Saving best model\n",
                        "Epoch: 0007 Batch: 50 /134 lost = 6.718029 ppl = 827.186\n",
                        "Epoch: 0007 Batch: 100 /134 lost = 6.669337 ppl = 787.873\n",
                        "Valid 4864 samples after epoch: 0007 lost = 6.775462 ppl = 876.084\n",
                        "Saving best model\n",
                        "Epoch: 0008 Batch: 50 /134 lost = 6.583679 ppl = 723.195\n",
                        "Epoch: 0008 Batch: 100 /134 lost = 6.550895 ppl = 699.87\n",
                        "Valid 4864 samples after epoch: 0008 lost = 6.692938 ppl = 806.689\n",
                        "Saving best model\n",
                        "Epoch: 0009 Batch: 50 /134 lost = 6.502550 ppl = 666.84\n",
                        "Epoch: 0009 Batch: 100 /134 lost = 6.478558 ppl = 651.032\n",
                        "Valid 4864 samples after epoch: 0009 lost = 6.648042 ppl = 771.272\n",
                        "Saving best model\n",
                        "Epoch: 0010 Batch: 50 /134 lost = 6.459141 ppl = 638.513\n",
                        "Epoch: 0010 Batch: 100 /134 lost = 6.440188 ppl = 626.525\n",
                        "Valid 4864 samples after epoch: 0010 lost = 6.627010 ppl = 755.22\n",
                        "Saving best model\n",
                        "Epoch: 0011 Batch: 50 /134 lost = 6.433589 ppl = 622.403\n",
                        "Epoch: 0011 Batch: 100 /134 lost = 6.418003 ppl = 612.778\n",
                        "Valid 4864 samples after epoch: 0011 lost = 6.617005 ppl = 747.702\n",
                        "Saving best model\n",
                        "Epoch: 0012 Batch: 50 /134 lost = 6.417160 ppl = 612.262\n",
                        "Epoch: 0012 Batch: 100 /134 lost = 6.403410 ppl = 603.901\n",
                        "Valid 4864 samples after epoch: 0012 lost = 6.611512 ppl = 743.606\n",
                        "Saving best model\n",
                        "Epoch: 0013 Batch: 50 /134 lost = 6.405841 ppl = 605.371\n",
                        "Epoch: 0013 Batch: 100 /134 lost = 6.391848 ppl = 596.959\n",
                        "Valid 4864 samples after epoch: 0013 lost = 6.608462 ppl = 741.342\n",
                        "Saving best model\n",
                        "Epoch: 0014 Batch: 50 /134 lost = 6.397621 ppl = 600.415\n",
                        "Epoch: 0014 Batch: 100 /134 lost = 6.381334 ppl = 590.715\n",
                        "Valid 4864 samples after epoch: 0014 lost = 6.605850 ppl = 739.408\n",
                        "Saving best model\n",
                        "Epoch: 0015 Batch: 50 /134 lost = 6.390524 ppl = 596.169\n",
                        "Epoch: 0015 Batch: 100 /134 lost = 6.372671 ppl = 585.62\n",
                        "Valid 4864 samples after epoch: 0015 lost = 6.604484 ppl = 738.399\n",
                        "Saving best model\n",
                        "Epoch: 0016 Batch: 50 /134 lost = 6.385429 ppl = 593.139\n",
                        "Epoch: 0016 Batch: 100 /134 lost = 6.364924 ppl = 581.101\n",
                        "Valid 4864 samples after epoch: 0016 lost = 6.603259 ppl = 737.495\n",
                        "Saving best model\n",
                        "Epoch: 0017 Batch: 50 /134 lost = 6.381797 ppl = 590.989\n",
                        "Epoch: 0017 Batch: 100 /134 lost = 6.358590 ppl = 577.432\n",
                        "Valid 4864 samples after epoch: 0017 lost = 6.602212 ppl = 736.723\n",
                        "Saving best model\n",
                        "Epoch: 0018 Batch: 50 /134 lost = 6.378034 ppl = 588.769\n",
                        "Epoch: 0018 Batch: 100 /134 lost = 6.352857 ppl = 574.13\n",
                        "Valid 4864 samples after epoch: 0018 lost = 6.602170 ppl = 736.692\n",
                        "Saving best model\n",
                        "Epoch: 0019 Batch: 50 /134 lost = 6.374303 ppl = 586.576\n",
                        "Epoch: 0019 Batch: 100 /134 lost = 6.347444 ppl = 571.031\n",
                        "Valid 4864 samples after epoch: 0019 lost = 6.602486 ppl = 736.925\n",
                        "Saving best model\n",
                        "Epoch: 0020 Batch: 50 /134 lost = 6.370846 ppl = 584.552\n",
                        "Epoch: 0020 Batch: 100 /134 lost = 6.340696 ppl = 567.191\n",
                        "Valid 4864 samples after epoch: 0020 lost = 6.602051 ppl = 736.604\n",
                        "Saving best model\n",
                        "Epoch: 0021 Batch: 50 /134 lost = 6.365831 ppl = 581.628\n",
                        "Epoch: 0021 Batch: 100 /134 lost = 6.334498 ppl = 563.686\n",
                        "Valid 4864 samples after epoch: 0021 lost = 6.601742 ppl = 736.377\n",
                        "Saving best model\n",
                        "Epoch: 0022 Batch: 50 /134 lost = 6.362264 ppl = 579.557\n",
                        "Epoch: 0022 Batch: 100 /134 lost = 6.329322 ppl = 560.776\n",
                        "Valid 4864 samples after epoch: 0022 lost = 6.602105 ppl = 736.644\n",
                        "Saving best model\n",
                        "Epoch: 0023 Batch: 50 /134 lost = 6.356716 ppl = 576.351\n",
                        "Epoch: 0023 Batch: 100 /134 lost = 6.326116 ppl = 558.981\n",
                        "Valid 4864 samples after epoch: 0023 lost = 6.601479 ppl = 736.183\n",
                        "Saving best model\n",
                        "Epoch: 0024 Batch: 50 /134 lost = 6.350335 ppl = 572.685\n",
                        "Epoch: 0024 Batch: 100 /134 lost = 6.321218 ppl = 556.25\n",
                        "Valid 4864 samples after epoch: 0024 lost = 6.600470 ppl = 735.441\n",
                        "Saving best model\n",
                        "Epoch: 0025 Batch: 50 /134 lost = 6.341908 ppl = 567.879\n",
                        "Epoch: 0025 Batch: 100 /134 lost = 6.314941 ppl = 552.769\n",
                        "Valid 4864 samples after epoch: 0025 lost = 6.598015 ppl = 733.637\n",
                        "Saving best model\n",
                        "Epoch: 0026 Batch: 50 /134 lost = 6.336232 ppl = 564.664\n",
                        "Epoch: 0026 Batch: 100 /134 lost = 6.310289 ppl = 550.204\n",
                        "Valid 4864 samples after epoch: 0026 lost = 6.595764 ppl = 731.988\n",
                        "Saving best model\n",
                        "Epoch: 0027 Batch: 50 /134 lost = 6.330965 ppl = 561.698\n",
                        "Epoch: 0027 Batch: 100 /134 lost = 6.303442 ppl = 546.45\n",
                        "Valid 4864 samples after epoch: 0027 lost = 6.593678 ppl = 730.462\n",
                        "Saving best model\n",
                        "Epoch: 0028 Batch: 50 /134 lost = 6.327102 ppl = 559.533\n",
                        "Epoch: 0028 Batch: 100 /134 lost = 6.298107 ppl = 543.542\n",
                        "Valid 4864 samples after epoch: 0028 lost = 6.592311 ppl = 729.465\n",
                        "Saving best model\n",
                        "Epoch: 0029 Batch: 50 /134 lost = 6.321002 ppl = 556.13\n",
                        "Epoch: 0029 Batch: 100 /134 lost = 6.290887 ppl = 539.632\n",
                        "Valid 4864 samples after epoch: 0029 lost = 6.589150 ppl = 727.162\n",
                        "Saving best model\n",
                        "Epoch: 0030 Batch: 50 /134 lost = 6.315259 ppl = 552.945\n",
                        "Epoch: 0030 Batch: 100 /134 lost = 6.284406 ppl = 536.146\n",
                        "Valid 4864 samples after epoch: 0030 lost = 6.587683 ppl = 726.097\n",
                        "Saving best model\n",
                        "Epoch: 0031 Batch: 50 /134 lost = 6.310288 ppl = 550.203\n",
                        "Epoch: 0031 Batch: 100 /134 lost = 6.279995 ppl = 533.786\n",
                        "Valid 4864 samples after epoch: 0031 lost = 6.587479 ppl = 725.949\n",
                        "Saving best model\n",
                        "Epoch: 0032 Batch: 50 /134 lost = 6.306143 ppl = 547.928\n",
                        "Epoch: 0032 Batch: 100 /134 lost = 6.275194 ppl = 531.229\n",
                        "Valid 4864 samples after epoch: 0032 lost = 6.587713 ppl = 726.118\n",
                        "Saving best model\n",
                        "Epoch: 0033 Batch: 50 /134 lost = 6.300905 ppl = 545.065\n",
                        "Epoch: 0033 Batch: 100 /134 lost = 6.269796 ppl = 528.37\n",
                        "Valid 4864 samples after epoch: 0033 lost = 6.588044 ppl = 726.358\n",
                        "Saving best model\n",
                        "Epoch: 0034 Batch: 50 /134 lost = 6.296607 ppl = 542.727\n",
                        "Epoch: 0034 Batch: 100 /134 lost = 6.265274 ppl = 525.985\n",
                        "Valid 4864 samples after epoch: 0034 lost = 6.588200 ppl = 726.472\n",
                        "Saving best model\n",
                        "Epoch: 0035 Batch: 50 /134 lost = 6.291993 ppl = 540.229\n",
                        "Epoch: 0035 Batch: 100 /134 lost = 6.260996 ppl = 523.741\n",
                        "Valid 4864 samples after epoch: 0035 lost = 6.588388 ppl = 726.609\n",
                        "Saving best model\n",
                        "Epoch: 0036 Batch: 50 /134 lost = 6.287001 ppl = 537.539\n",
                        "Epoch: 0036 Batch: 100 /134 lost = 6.256929 ppl = 521.615\n",
                        "Valid 4864 samples after epoch: 0036 lost = 6.588060 ppl = 726.371\n",
                        "Saving best model\n",
                        "Epoch: 0037 Batch: 50 /134 lost = 6.281116 ppl = 534.385\n",
                        "Epoch: 0037 Batch: 100 /134 lost = 6.251184 ppl = 518.627\n",
                        "Valid 4864 samples after epoch: 0037 lost = 6.588528 ppl = 726.71\n",
                        "Saving best model\n",
                        "Epoch: 0038 Batch: 50 /134 lost = 6.277430 ppl = 532.418\n",
                        "Epoch: 0038 Batch: 100 /134 lost = 6.247062 ppl = 516.493\n",
                        "Valid 4864 samples after epoch: 0038 lost = 6.589114 ppl = 727.136\n",
                        "Saving best model\n",
                        "Epoch: 0039 Batch: 50 /134 lost = 6.273662 ppl = 530.416\n",
                        "Epoch: 0039 Batch: 100 /134 lost = 6.242797 ppl = 514.295\n",
                        "Valid 4864 samples after epoch: 0039 lost = 6.589884 ppl = 727.697\n",
                        "Saving best model\n",
                        "Epoch: 0040 Batch: 50 /134 lost = 6.269874 ppl = 528.411\n",
                        "Epoch: 0040 Batch: 100 /134 lost = 6.237194 ppl = 511.421\n",
                        "Valid 4864 samples after epoch: 0040 lost = 6.588758 ppl = 726.878\n",
                        "Saving best model\n",
                        "Epoch: 0041 Batch: 50 /134 lost = 6.263988 ppl = 525.31\n",
                        "Epoch: 0041 Batch: 100 /134 lost = 6.219879 ppl = 502.642\n",
                        "Valid 4864 samples after epoch: 0041 lost = 6.582985 ppl = 722.693\n",
                        "Saving best model\n",
                        "Epoch: 0042 Batch: 50 /134 lost = 6.258874 ppl = 522.63\n",
                        "Epoch: 0042 Batch: 100 /134 lost = 6.212606 ppl = 499.0\n",
                        "Valid 4864 samples after epoch: 0042 lost = 6.582975 ppl = 722.686\n",
                        "Saving best model\n",
                        "Epoch: 0043 Batch: 50 /134 lost = 6.253089 ppl = 519.616\n",
                        "Epoch: 0043 Batch: 100 /134 lost = 6.208207 ppl = 496.81\n",
                        "Valid 4864 samples after epoch: 0043 lost = 6.583166 ppl = 722.824\n",
                        "Saving best model\n",
                        "Epoch: 0044 Batch: 50 /134 lost = 6.248000 ppl = 516.978\n",
                        "Epoch: 0044 Batch: 100 /134 lost = 6.204329 ppl = 494.887\n",
                        "Valid 4864 samples after epoch: 0044 lost = 6.583488 ppl = 723.057\n",
                        "Saving best model\n",
                        "Epoch: 0045 Batch: 50 /134 lost = 6.242966 ppl = 514.382\n",
                        "Epoch: 0045 Batch: 100 /134 lost = 6.199949 ppl = 492.724\n",
                        "Valid 4864 samples after epoch: 0045 lost = 6.583659 ppl = 723.181\n",
                        "Saving best model\n",
                        "Epoch: 0046 Batch: 50 /134 lost = 6.239528 ppl = 512.617\n",
                        "Epoch: 0046 Batch: 100 /134 lost = 6.195353 ppl = 490.464\n",
                        "Valid 4864 samples after epoch: 0046 lost = 6.583840 ppl = 723.312\n",
                        "Saving best model\n",
                        "Epoch: 0047 Batch: 50 /134 lost = 6.235722 ppl = 510.669\n",
                        "Epoch: 0047 Batch: 100 /134 lost = 6.191098 ppl = 488.382\n",
                        "Valid 4864 samples after epoch: 0047 lost = 6.583768 ppl = 723.259\n",
                        "Saving best model\n",
                        "Epoch: 0048 Batch: 50 /134 lost = 6.231997 ppl = 508.77\n",
                        "Epoch: 0048 Batch: 100 /134 lost = 6.186165 ppl = 485.979\n",
                        "Valid 4864 samples after epoch: 0048 lost = 6.584560 ppl = 723.833\n",
                        "Saving best model\n",
                        "Epoch: 0049 Batch: 50 /134 lost = 6.228168 ppl = 506.826\n",
                        "Epoch: 0049 Batch: 100 /134 lost = 6.181338 ppl = 483.639\n",
                        "Valid 4864 samples after epoch: 0049 lost = 6.585547 ppl = 724.548\n",
                        "Saving best model\n",
                        "Epoch: 0050 Batch: 50 /134 lost = 6.224568 ppl = 505.005\n",
                        "Epoch: 0050 Batch: 100 /134 lost = 6.176664 ppl = 481.383\n",
                        "Valid 4864 samples after epoch: 0050 lost = 6.586440 ppl = 725.195\n",
                        "Saving best model\n",
                        "Epoch: 0051 Batch: 50 /134 lost = 6.221161 ppl = 503.287\n",
                        "Epoch: 0051 Batch: 100 /134 lost = 6.172522 ppl = 479.393\n",
                        "Valid 4864 samples after epoch: 0051 lost = 6.587828 ppl = 726.202\n",
                        "Saving best model\n",
                        "Epoch: 0052 Batch: 50 /134 lost = 6.218133 ppl = 501.766\n",
                        "Epoch: 0052 Batch: 100 /134 lost = 6.168721 ppl = 477.575\n",
                        "Valid 4864 samples after epoch: 0052 lost = 6.589241 ppl = 727.229\n",
                        "Saving best model\n",
                        "Epoch: 0053 Batch: 50 /134 lost = 6.215052 ppl = 500.222\n",
                        "Epoch: 0053 Batch: 100 /134 lost = 6.164383 ppl = 475.508\n",
                        "Valid 4864 samples after epoch: 0053 lost = 6.590196 ppl = 727.923\n",
                        "Saving best model\n",
                        "Epoch: 0054 Batch: 50 /134 lost = 6.211576 ppl = 498.486\n",
                        "Epoch: 0054 Batch: 100 /134 lost = 6.159343 ppl = 473.117\n",
                        "Valid 4864 samples after epoch: 0054 lost = 6.591259 ppl = 728.698\n",
                        "Saving best model\n",
                        "Epoch: 0055 Batch: 50 /134 lost = 6.208369 ppl = 496.89\n",
                        "Epoch: 0055 Batch: 100 /134 lost = 6.155646 ppl = 471.371\n",
                        "Valid 4864 samples after epoch: 0055 lost = 6.592397 ppl = 729.527\n",
                        "Saving best model\n",
                        "Epoch: 0056 Batch: 50 /134 lost = 6.205437 ppl = 495.436\n",
                        "Epoch: 0056 Batch: 100 /134 lost = 6.152105 ppl = 469.705\n",
                        "Valid 4864 samples after epoch: 0056 lost = 6.593787 ppl = 730.542\n",
                        "Saving best model\n",
                        "Epoch: 0057 Batch: 50 /134 lost = 6.201878 ppl = 493.675\n",
                        "Epoch: 0057 Batch: 100 /134 lost = 6.148435 ppl = 467.984\n",
                        "Valid 4864 samples after epoch: 0057 lost = 6.595121 ppl = 731.517\n",
                        "Saving best model\n",
                        "Epoch: 0058 Batch: 50 /134 lost = 6.197265 ppl = 491.403\n",
                        "Epoch: 0058 Batch: 100 /134 lost = 6.144104 ppl = 465.962\n",
                        "Valid 4864 samples after epoch: 0058 lost = 6.595278 ppl = 731.632\n",
                        "Saving best model\n",
                        "Epoch: 0059 Batch: 50 /134 lost = 6.193217 ppl = 489.418\n",
                        "Epoch: 0059 Batch: 100 /134 lost = 6.140406 ppl = 464.242\n",
                        "Valid 4864 samples after epoch: 0059 lost = 6.596779 ppl = 732.731\n",
                        "Saving best model\n",
                        "Epoch: 0060 Batch: 50 /134 lost = 6.190318 ppl = 488.001\n",
                        "Epoch: 0060 Batch: 100 /134 lost = 6.135252 ppl = 461.855\n",
                        "Valid 4864 samples after epoch: 0060 lost = 6.593907 ppl = 730.63\n",
                        "Saving best model\n",
                        "\n",
                        "Test the RNNLM……………………\n",
                        "Test 5760 samples with models/3_layers_rnnlm_model_best.ckpt……………………\n",
                        "lost = 6.501674 ppl = 666.256\n"
                    ]
                }
            ],
            "source": [
                "!python n_layers_rnnlm_with_penn_assignment(default_n=3).py"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.12 ('torch111')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "7d4a78585e453c285cdcd9b397bf3fdbf88591a79b8f78f641dda4ea59398329"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}